{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score challenge submission\n",
    "\n",
    "This notebook produces scores for a custom challenge set.  It scores each tasks and provides a summary score (average).\n",
    "\n",
    "This is designed to help compare the quality of a solution against a challenge set under our control and demonstrate that the aicrowd score is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge=\"ex2-from-21k-train-with-pids\"\n",
    "submitdir=\"/home/jpr/projects/mpd-challenge-aicrowd/\"\n",
    "submissionfile=\"method-01-mympd-2nd-21k-2021-11-14.csv.gz\"\n",
    "submissions = [{\"tag\": \"vl6\", \"file\": submissionfile}]\n",
    "submissionfile=\"method-02-mympd-2nd-21k-2021-11-07.csv.gz\"\n",
    "submissions.append({\"tag\": \"hw\", \"file\": submissionfile})\n",
    "submissionfile=\"method-u2uknn-mympd-mpd-2nd-21k-2021-12-12.csv.gz\"\n",
    "submissions.append({\"tag\": \"u2uknn\", \"file\": submissionfile})\n",
    "submissionfile=\"method-u2uknn-mympd-full-mympd-full-20k-2021-12-29.csv.gz\"\n",
    "submissions.append({\"tag\": \"u2uknnfull\", \"file\": submissionfile})\n",
    "submissionfile=\"method-i2iknn-mympd-mpd-2nd-21k-2021-12-18.csv.gz\"\n",
    "submissions.append({\"tag\": \"i2iknn\", \"file\": submissionfile})\n",
    "submissionfile=\"method-mfals-mympd-mpd-2nd-21k-2021-12-26.csv.gz\"\n",
    "submissions.append({\"tag\": \"mfals\", \"file\": submissionfile})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files={\"vl6\": \"method-01-mympd-2nd-21k-2021-11-14.csv.gz\",\n",
    "        \"hw\": \"method-02-mympd-2nd-21k-2021-11-07.csv.gz\",\n",
    "        \"u2uknn\": \"method-u2uknn-mympd-mpd-2nd-21k-2021-12-12.csv.gz\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the no holdouts challenge set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/{}/challenge_set_noholdout.json'.format(challenge),'r') as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noholdout = pd.json_normalize(data,\"playlists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noholdout.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder noholdouts to group sequential and random tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf=noholdout[0:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf=tmpdf.append(noholdout[7000:8000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf=tmpdf.append(noholdout[6000:7000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf=tmpdf.append(noholdout[8000:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf.task_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noholdout=tmpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/{}/challenge_set_noholdout.json'.format(\"mympd-full\"),'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "    \n",
    " \n",
    "noholdout2 = pd.json_normalize(data,\"playlists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_holdout(noholdout):\n",
    "    tmpdf=noholdout[0:6000]\n",
    "    tmpdf=tmpdf.append(noholdout[7000:8000])\n",
    "    tmpdf=tmpdf.append(noholdout[6000:7000])\n",
    "    tmpdf=tmpdf.append(noholdout[8000:10000])\n",
    "    return tmpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noholdout2=reorder_holdout(noholdout2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load challenge submission`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectracks=pd.read_csv('{}/{}'.format(submitdir, submissionfile), header=None, skiprows=1, index_col=0, skipinitialspace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the pids match those of the challenge set.  In the case of mympd the pid range starts at 200000 and goes up in sequence of noholdout data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectracks = rectracks.sort_values(by=0, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Challenge Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startpid=2000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-precision is the fraction of correctly recommended tracks in the ground truth playlist as described on [the challenge site](https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge#evaluation)\n",
    "    \n",
    "\n",
    "Use the [r-precesion calculation from the hello_world metrics](https://github.com/jprorama/spotify_recSys_challenge_2018/blob/f33d82715190a20fdbc998c9ff709bcabd62a55e/utils/metrics.py#L26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r_precision(answer, cand):\n",
    "    set_answer = set(answer)\n",
    "    r = len(set_answer&set(cand[:len(set_answer)])) / len(set_answer)\n",
    "    return r\n",
    "\n",
    "def get_ndcg(answer, cand):\n",
    "    cand_len = len(cand) \n",
    "    idcg=0\n",
    "    dcg=0\n",
    "    \n",
    "    #print(\"cand len {}\".format(cand_len))\n",
    "    #print(\"ans len {}\".format(len(answer)))\n",
    "    #print(\"cand: {}\".format(cand))\n",
    "    \n",
    "    for i in range(cand_len):\n",
    "        #print(\"i {}\".format(i))\n",
    "        #print(\"cand {}\".format(cand[i]))\n",
    "        if cand[i] in answer: \n",
    "            dcg += (1/math.log(i+1+1,2))\n",
    "\n",
    "    for i in range(len(set(answer))):\n",
    "        idcg += (1/math.log(i+1+1,2))\n",
    "    \n",
    "    return dcg/idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realtracks=pd.DataFrame()\n",
    "rprec_sum = 0.0\n",
    "ndcg_sum = 0.0\n",
    "rprec_match = 0\n",
    "ndcg_match = 0\n",
    "\n",
    "for i in range(len(noholdout)):\n",
    "    pid = startpid + i\n",
    "    #print(\"pid={}\".format(pid))\n",
    "    gttracks = [track[\"track_uri\"] for track in noholdout[noholdout[\"challenge_pid\"]==pid].tracks.to_list()[0]]\n",
    "    candtracks = rectracks.loc[pid].to_list()\n",
    "    rprec = get_r_precision(gttracks, candtracks)\n",
    "    rprec_sum = rprec_sum + rprec\n",
    "    if rprec > 0:\n",
    "        rprec_match += 1\n",
    "    ndcg = get_ndcg(gttracks, candtracks)\n",
    "    ndcg_sum = ndcg_sum + ndcg\n",
    "    if ndcg > 0:\n",
    "        ndcg_match += 1\n",
    "    \n",
    "print(\"rprec = {}\".format(rprec_sum/len(noholdout)))\n",
    "print(\"ndcg = {}\".format(ndcg_sum/len(noholdout)))\n",
    "print(\"rprec_match = {}\".format(rprec_match))\n",
    "print(\"ndcg_match = {}\".format(ndcg_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_set(answer, candidates):\n",
    "    rprec_sum = 0.0\n",
    "    ndcg_sum = 0.0\n",
    "    rprec_match = 0\n",
    "    ndcg_match = 0\n",
    "\n",
    "    scores = dict()\n",
    "\n",
    "    for pid in answer.challenge_pid:\n",
    "        #pid = startpid + i\n",
    "        #print(\"pid={}\".format(pid))\n",
    "        gttracks = [track[\"track_uri\"] for track in answer[answer[\"challenge_pid\"]==pid].tracks.to_list()[0]]\n",
    "        candtracks = candidates.loc[pid].to_list()\n",
    "        rprec = get_r_precision(gttracks, candtracks)\n",
    "        rprec_sum = rprec_sum + rprec\n",
    "        if rprec > 0:\n",
    "            rprec_match += 1\n",
    "        ndcg = get_ndcg(gttracks, candtracks)\n",
    "        ndcg_sum = ndcg_sum + ndcg\n",
    "        if ndcg > 0:\n",
    "            ndcg_match += 1\n",
    "        \n",
    "    scores[\"rprec\"] = rprec_sum/len(answer)\n",
    "    scores[\"rprec_match\"] = rprec_match\n",
    "    scores[\"ndcg\"] = ndcg_sum/len(answer)\n",
    "    scores[\"ndcg_match\"] = ndcg_match\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprec_sum = 0.0\n",
    "ndcg_sum = 0.0\n",
    "rprec_match = 0\n",
    "ndcg_match = 0\n",
    "\n",
    "scores = dict()\n",
    "\n",
    "for task in noholdout.task_name.drop_duplicates():\n",
    "\n",
    "    scores[task] = score_set(noholdout[noholdout[\"task_name\"]==task], rectracks)\n",
    "    \n",
    "    rprec_sum += scores[task][\"rprec\"]\n",
    "    rprec_match += scores[task][\"rprec_match\"]\n",
    "    ndcg_sum += scores[task][\"ndcg\"]\n",
    "    ndcg_match += scores[task][\"ndcg_match\"]\n",
    "    \n",
    "    \n",
    "    print(\"task: {}\".format(task))\n",
    "    print(\"rprec = {}\".format(scores[task][\"rprec\"]))\n",
    "    print(\"ndcg = {}\".format(scores[task][\"ndcg\"]))\n",
    "    print(\"rprec_match = {}\".format(scores[task][\"rprec_match\"]))\n",
    "    print(\"ndcg_match = {}\".format(scores[task][\"ndcg_match\"]))\n",
    "    print(\"\\n\")\n",
    "\n",
    "scores[\"total\"] = dict()\n",
    "scores[\"total\"][\"rprec\"] = rprec_sum/10\n",
    "scores[\"total\"][\"rprec_match\"] = rprec_match\n",
    "scores[\"total\"][\"ndcg\"] = ndcg_sum/10\n",
    "scores[\"total\"][\"ndcg_match\"] = ndcg_match\n",
    "\n",
    "print(\"task: {}\".format(\"total\"))\n",
    "print(\"rprec = {}\".format(scores[\"total\"][\"rprec\"]))\n",
    "print(\"ndcg = {}\".format(scores[\"total\"][\"ndcg\"]))\n",
    "print(\"rprec_match = {}\".format(scores[\"total\"][\"rprec_match\"]))\n",
    "print(\"ndcg_match = {}\".format(scores[\"total\"][\"ndcg_match\"]))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_setdf(answer, candidate):\n",
    "\n",
    "    rprec_sum = 0.0\n",
    "    ndcg_sum = 0.0\n",
    "    rprec_match = 0\n",
    "    ndcg_match = 0\n",
    "\n",
    "    results = answer.copy()\n",
    "\n",
    "    #results[\"candidates\"] = \n",
    "    results[\"rprec\"] = 0\n",
    "    results[\"ndcg\"] = 0\n",
    "\n",
    "    for pid in results.challenge_pid:\n",
    "        #pid = startpid + i\n",
    "        #print(\"pid={}\".format(pid))\n",
    "        gttracks = [track[\"track_uri\"] for track in results[results[\"challenge_pid\"]==pid].tracks.to_list()[0]]\n",
    "        candtracks = rectracks.loc[pid].to_list()\n",
    "        rprec = get_r_precision(gttracks, candtracks)\n",
    "        rprec_sum = rprec_sum + rprec\n",
    "        if rprec > 0:\n",
    "            rprec_match += 1\n",
    "        ndcg = get_ndcg(gttracks, candtracks)\n",
    "        ndcg_sum = ndcg_sum + ndcg\n",
    "        if ndcg > 0:\n",
    "            ndcg_match += 1\n",
    "\n",
    "        #results.at[results[\"challenge_pid\"]==pid, \"candidates\"] = candtracks\n",
    "        results.at[results[\"challenge_pid\"]==pid, \"rprec\"] = rprec\n",
    "        results.at[results[\"challenge_pid\"]==pid, \"ndcg\"] = ndcg\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rlist=[]\n",
    "results = pd.DataFrame()\n",
    "tmpdf = pd.DataFrame()\n",
    "\n",
    "for submission in submissions:\n",
    "    print(\"submission: {}\".format(submission))\n",
    "    print(\"file: {}\".format(submission[\"file\"]))\n",
    "    rectracks=pd.read_csv('{}/{}'.format(submitdir, submission[\"file\"]), header=None, skiprows=1, index_col=0, skipinitialspace=True)\n",
    "    if (submission[\"tag\"]==\"u2uknnfull\"):\n",
    "        tmpdf = score_setdf(noholdout2, rectracks)\n",
    "    else:    \n",
    "        tmpdf = score_setdf(noholdout, rectracks)\n",
    "    print(\"tmpdf len: {}\".format(len(tmpdf)))\n",
    "    tmpdf[\"tag\"]=submission[\"tag\"]\n",
    "    rlist.append(tmpdf)\n",
    "    \n",
    "results=pd.concat(rlist)\n",
    "results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby([\"tag\", \"task_name\"]).rprec.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize total peformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby([\"tag\"]).rprec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby([\"tag\"]).ndcg.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rand100 which is the task which most significantly differentiates method performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results.task_name!=\"rand_100_title\"].groupby([\"tag\"]).rprec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results.task_name!=\"rand_100_title\"].groupby([\"tag\"]).ndcg.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodup = results[results[\"tag\"]==\"vl6\"].drop_duplicates(subset=\"pid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodup = nodup.append(results[results[\"tag\"]==\"hw\"].drop_duplicates(subset=\"pid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodup = nodup.append(results[results[\"tag\"]==\"u2uknn\"].drop_duplicates(subset=\"pid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodup = nodup.append(results[results[\"tag\"]==\"u2uknnfull\"].drop_duplicates(subset=\"pid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodup = nodup.append(results[results[\"tag\"]==\"i2iknn\"].drop_duplicates(subset=\"pid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodup = nodup.append(results[results[\"tag\"]==\"mfals\"].drop_duplicates(subset=\"pid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodup.groupby([\"tag\", \"task_name\"]).rprec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means= nodup.groupby([\"tag\", \"task_name\"]).rprec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax=means.vl6.plot.bar(legend=True, color=\"blue\", alpha=.35)\n",
    "means.hw.plot.bar(ax=ax,legend=True, color=\"red\", alpha=0.35)\n",
    "means.u2uknn.plot.bar(ax=ax,legend=True, color=\"purple\", alpha=0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create means as dataframe rather than groupby object by using the aggregator on the groupby object rather than the series of rprec column alone.  This keeps the column names and should simplify plotting.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = nodup[[\"tag\", \"task_name\",\"rprec\"]].groupby([\"tag\", \"task_name\"], sort=False).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x = \"task_name\",       # x variable name\n",
    "            y = \"rprec\",       # y variable name\n",
    "            hue = \"tag\",  # group variable name\n",
    "            data = means,     # dataframe to plot\n",
    "            kind = \"bar\",\n",
    "            aspect = 2)\n",
    "ignore=plt.xticks(rotation=45)\n",
    "ignore=plt.title(\"R-Precision Compared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = nodup[[\"tag\", \"task_name\",\"ndcg\"]].groupby([\"tag\", \"task_name\"], sort=False).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x = \"task_name\",       # x variable name\n",
    "            y = \"ndcg\",       # y variable name\n",
    "            hue = \"tag\",  # group variable name\n",
    "            data = means,     # dataframe to plot\n",
    "            kind = \"bar\",\n",
    "            aspect = 2)\n",
    "ignore=plt.xticks(rotation=45)\n",
    "ignore=plt.title(\"NDCG Compared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Violin plot\n",
    "\n",
    "start with the routine used during the recsys18 analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violin(df, title=\"Violin Plot\"):\n",
    "    #sns.set_style(\"white\") \n",
    "    sns.set(rc={'figure.figsize':(8,6)})\n",
    "    g = sns.violinplot(data=df, cut=0, orient='v', scale='width')\n",
    "    #g = sns.violinplot(x=df.iloc[,0], y=df.iloc[0,:], cut=0, scale='width')\n",
    "    g.set_title(title)\n",
    "    #g.set_xlabel(\"Subtask\")\n",
    "    g.set_ylabel(\"Score\")\n",
    "    g.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodup.groupby([\"tag\", \"task_name\"]).rprec.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't need the describe data because that will come from the violin plot.  Just need to use all the raw data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vl6desc = nodup[nodup[\"tag\"]==\"vl6\"][[\"task_name\", \"rprec\"]] #.groupby([\"task_name\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwdesc = nodup[nodup[\"tag\"]==\"hw\"][[\"task_name\", \"rprec\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_violin(vl6desc[vl6desc[\"task_name\"]==\"rand_100_title\"], \"rand_100_title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_violin(hwdesc[hwdesc[\"task_name\"]==\"rand_100_title\"], \"rand_100_title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore side-by-side plots\n",
    "\n",
    "What to take all the tasks and see the teams side by side\n",
    "\n",
    "Create violin plots for each task. https://stackoverflow.com/a/47487445/8928529\n",
    "\n",
    "Basically loop through the tasks and plot on each subplot axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 2, figsize=(20, 32), sharey='row')\n",
    "axes_cols = (axes.flatten()[::2], axes.flatten()[1::2])\n",
    "\n",
    "i=0\n",
    "for task in vl6desc.task_name.drop_duplicates():\n",
    "    \n",
    "    ax=axes_cols[0][i]\n",
    "    sns.violinplot(data=vl6desc[vl6desc[\"task_name\"]==task], cut=0, orient='v', scale='width', ax=ax)\n",
    "    ax.set_title('task = {}'.format(task), y=0.95)\n",
    "    ax=axes_cols[1][i]\n",
    "    sns.violinplot(data=hwdesc[hwdesc[\"task_name\"]==task], cut=0, orient='v', scale='width', ax=ax)\n",
    "    ax.set_title('task = {}'.format(task), y=0.95)\n",
    "    \n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore split plot\n",
    "\n",
    "This lets me see the data paired directly and allows easier visual comparison of differences.\n",
    "\n",
    "The test rand_100_title task shows clear differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nodup[((nodup[\"tag\"]==\"vl6\") | (nodup[\"tag\"]==\"hw\"))][[\"tag\",\"task_name\", \"rprec\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(data=data[data[\"task_name\"]==\"rand_100_title\"], cut=0, orient='v', scale='width',\n",
    "               x=\"task_name\", y=\"rprec\",\n",
    "               hue=\"tag\",\n",
    "               split=True, inner=\"quart\")\n",
    "\n",
    "#sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprec_data = nodup[((nodup[\"tag\"]==\"vl6\") | (nodup[\"tag\"]==\"hw\"))][[\"tag\",\"task_name\", \"rprec\"]]\n",
    "ndcg_data  = nodup[((nodup[\"tag\"]==\"vl6\") | (nodup[\"tag\"]==\"hw\"))][[\"tag\",\"task_name\", \"ndcg\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 2, figsize=(20, 32), sharey='row')\n",
    "axes_cols = (axes.flatten()[::2], axes.flatten()[1::2])\n",
    "\n",
    "i=0\n",
    "for task in vl6desc.task_name.drop_duplicates():\n",
    "    \n",
    "    ax=axes_cols[0][i]\n",
    "    sns.violinplot(data=rprec_data[rprec_data[\"task_name\"]==task], cut=0, orient='v', scale='width',\n",
    "               x=\"task_name\", y=\"rprec\",\n",
    "               hue=\"tag\",\n",
    "               split=True, inner=\"quart\", ax=ax)\n",
    "    ax.set_title('task = {}'.format(task), y=0.95)\n",
    "\n",
    "    ax=axes_cols[1][i]\n",
    "    sns.violinplot(data=ndcg_data[ndcg_data[\"task_name\"]==task], cut=0, orient='v', scale='width',\n",
    "               x=\"task_name\", y=\"ndcg\",\n",
    "               hue=\"tag\",\n",
    "               split=True, inner=\"quart\", ax=ax)\n",
    "    ax.set_title('task = {}'.format(task), y=0.95)\n",
    "    \n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the rprec and ndcg data plotted side by side it is clear that the rand_100_title was much more effectively solved by vl6.\n",
    "\n",
    "The second most effective was first_1_title where vl6 had higher mean.\n",
    "\n",
    "However the the title_only solution of hw is clearly better.\n",
    "\n",
    "All the rest of the tasks had nearly identical means and distributions with the hw solution having slightly higher ndcg in those tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprec_data = nodup[[\"tag\",\"task_name\", \"rprec\"]]\n",
    "ndcg_data  = nodup[[\"tag\",\"task_name\", \"ndcg\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprec_data=rprec_data.reset_index().rename(columns={\"index\": \"pid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprec_data[((rprec_data[\"tag\"]==\"vl6\") & (rprec_data[\"task_name\"]==\"first_1_title\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=rprec_data[((rprec_data[\"tag\"]==\"vl6\") & (rprec_data[\"task_name\"]==\"first_1_title\"))], x='pid', y=\"rprec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=rprec_data[((rprec_data[\"tag\"]==\"hw\") & (rprec_data[\"task_name\"]==\"first_1_title\"))], x='pid', y=\"rprec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=rprec_data[((rprec_data[\"tag\"]==\"vl6\"))], x=\"pid\", y=\"rprec\", hue=\"tag\", alpha=.5)\n",
    "#sns.scatterplot(data=rprec_data[((rprec_data[\"tag\"]==\"hw\"))], y=\"rprec\", hue=\"tag\", alpha=.5, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=rprec_data, x=\"pid\", y=\"rprec\", hue=\"tag\", alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's much easier to get fast insight from seaborn using facet grids since they are built right from the data.\n",
    "\n",
    "https://seaborn.pydata.org/tutorial/axis_grids.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(rprec_data, row=\"task_name\", col=\"tag\", hue=\"tag\", margin_titles=True, height=4, aspect=2)\n",
    "g.map(sns.scatterplot, \"pid\", \"rprec\", linewidth = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprec_data[\"rpid\"]= rprec_data.pid % 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(rprec_data, row=\"task_name\", col=\"tag\", hue=\"tag\", margin_titles=True, height=3, aspect=2)\n",
    "g.map(sns.scatterplot, \"rpid\", \"rprec\", linewidth = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisit violin distribution plots now with all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(rprec_data, row=\"task_name\", hue=\"tag\", margin_titles=True, height=3, aspect=4)\n",
    "g.map(sns.violinplot, \"tag\", \"rprec\", order=['vl6', 'hw', 'u2uknn', 'u2uknnfull','i2iknn','mfals'], palette=\"muted\", inner=\"quart\", cut=0, orient='v', scale='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Inspect the highest scoring recommendations\n",
    "\n",
    "Understand which tasks and methods perform the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodup[nodup.rprec > 0.8][[\"rprec\", \"ndcg\", \"tag\",\"task_name\", \"name\", \"num_tracks\"]]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
