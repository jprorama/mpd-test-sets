{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-to-user Collaborative Filtering\n",
    "\n",
    "Create a basic user-to-user K-nearest neighbors (u2uknn) collaboritive filtering solution for recommended tracks.\n",
    "This is built from the Verstrepen2017 matrix notation of a score matrix factored by user-to-user similarity and the ratings matrix.\n",
    "\n",
    "    Score = Similarity x Ratings \n",
    "    \n",
    "The similarity and ratings matrix are built from an append of the challenge set to the training set.\n",
    "This is required by KNN because the similarity computation is of each individual challenge playlist against all the training set.\n",
    "In this formulation we technically also include the other training set similarities in the final score.\n",
    "This simplifies the computation and dimension managment and avoids having to loop on individual challenge playlist and training set pairings.\n",
    "We assume that the impact on final scores is minimal.\n",
    "\n",
    "The cold start task is address with a simple global popularity ranking of tracks.\n",
    "We compute the global popularity of tracks and recommend the first 500 in ranked order.\n",
    "This set is also included as backfill to each playlist recommendation accross all subtasks to ensure the minimum 500 tracks are available to each challenge solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters for Run\n",
    "\n",
    "These parameters control the selection of dataset, challenge set, and solution output.\n",
    "\n",
    "Must select dataset and challege_name.  The rest are derived parameters and can be left alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the directory with different collections of training and test sets\n",
    "datadir=\"data/\"  # path to base data set\n",
    "\n",
    "# select the data for training  \n",
    "#dataset=\"mpd/data\"     # the original full mpd training set, requires quick=True and max_files set\n",
    "#dataset=\"mpd-1st-21k\"  # first 21 files of mpd, equiv to quick=True and max_files 20\n",
    "#dataset=\"mpd-2nd-21k\"  # second 21 files of mpd, avoids using data that built mympd challenge set\n",
    "dataset=\"mympd-full-20k\"\n",
    "\n",
    "# select data for testing, this is the challenge_set.json file for specific challenge data\n",
    "#challenge_name=\"mpd\"  # original mpd challenge set, use with aicrowd\n",
    "#challenge_name=\"mympd\"  # my custom challenge set for task analysis\n",
    "challenge_name=\"mympd-full\"  # my custom challenge sampled from full training set for task analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The papermill parameter cell needs to set variables exclusively before they can be used.  The CLI parameters are injected in a cell after the parameters cell.  The parameters can't be used until after the injected cell, otherwise they just get the static default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derived parameters, no need to change.\n",
    "\n",
    "#trainset=\"data/mpd/data\"  # relative path to training set in slice json file format\n",
    "trainset=datadir+dataset+\"/data\"  # relative path to training set in slice json file format\n",
    "\n",
    "#testset=\"data/challenge_set.json\" # relative path to test set in challenge_set.json format\n",
    "#testset=datadir+challenge_name+\"-challenge-set/challenge_set.json\" # relative path to test set in challenge_set.json format\n",
    "testset=datadir+challenge_name+\"/challenge_set.json\" # relative path to test set in challenge_set.json format\n",
    "\n",
    "datestr=date.isoformat(date.today())\n",
    "\n",
    "challenge_header = \"team_info,jprorama,jprorama@gmail.com\\n\"\n",
    "challenge_solution = \"method-u2uknn-\"+challenge_name+\"-\"+dataset+\"-\"+datestr+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate more verbose output for some functions\n",
    "debug = True\n",
    "\n",
    "# parameters for mpd load, superceeded by mpd-1st-21k\n",
    "quick = False\n",
    "max_files_for_quick_processing = 20\n",
    "\n",
    "# random state\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the mpd training data\n",
    "\n",
    "Create data frame for playlists and tracks to make it simple to work with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "playlists, tracks = utils.process_mpd(trainset, quick, maxfiles=max_files_for_quick_processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a new index for playlists so each row has unique id using pid. After reading the slice files the index values repeat for each slice.\n",
    "\n",
    "Preference is to not use the pid since that drops this data column.\n",
    "Instead create a new column of integers for each row and then set that as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = playlists.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = playlists[[\"pid\",\"tracks\"]].explode(\"tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl[\"track_uri\"] = [d.get(\"track_uri\") for d in pl.tracks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl[\"artist_name\"] = [d.get(\"artist_name\") for d in pl.tracks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expanded one-row-per-track representation shows we have 1.4million songs (rows). The row index has 21k entries which matches the 21k playlists in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pl[[\"track_uri\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From example in [pandas sparse data types page](https://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html) use memory_usage().sum().  Not clear why we divide by 1000.  Would think that makes it kilobytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'dense : {:0.2f} kbytes'.format(tracks.memory_usage().sum() / 1e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot encode playlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to use get_dummies() works in the dense space an tries to build a dataframe of 100k by 1.4Million songs.  Not sure why so many rows but it's still to big for ram at 300+G\n",
    "\n",
    "trackhots = pd.get_dummies(tracks, dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn has a onehot encoder that is a preprocessor to many of its routines.  See if we can fit the tracks to this representaiton.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pl[[\"pid\", \"track_uri\"]].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trackhots = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trackhots.fit(pl[[\"pid\", \"track_uri\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trackhots.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trackhots.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the original data into a matrix representation.\n",
    "\n",
    "Here again is the 1.4x290k represenation.  The 1.4k is the songs, so rows in the original matrix but not clear where the 290k comes from.  Would expect 21k for the playlists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "th = trackhots.transform(pl[[\"pid\",\"track_uri\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pl[\"pid\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "playlists[\"num_tracks\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, there are some problems in the transformation.  The 1.4mil comes from the total number of tracks in training.  The total unique is much smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pl[\"track_uri\"].drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd expect an transformed data set to be 21k by 269k.\n",
    "\n",
    "Ah, the onehot encoder wants a feature set of each record with its distinct features.\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features\n",
    "\n",
    "in this case it's rows of track_uri.\n",
    "so each row with mapp to the idx value and will just have tracks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "playlists.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pl[[\"track_uri\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try converting each tracks string to a data type \n",
    "\n",
    "https://www.geeksforgeeks.org/python-convert-string-dictionary-to-dictionary/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "playlists[[\"tracks\"]].tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a list of lists. This is pretty easy to construct with a list comprehension to wrap the lists into a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pltracks = [d for d in playlists[[\"tracks\"]].tracks.apply((lambda s: [d[\"track_uri\"] for d in s]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(pltracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type(pltracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what we are really trying to do is train the encoding and then transform each row.\n",
    "\n",
    "this is more like having a vocabulary and different sentances.\n",
    "I need to map each sentance to it's onehot encoding of the vocabulary.\n",
    "\n",
    "this example shows moving from an integerencoding to a one hot encoding\n",
    "https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "\n",
    "reading the docs leads to multi label binarizer which appears to be closer to what i want.\n",
    "https://scikit-learn.org/stable/modules/preprocessing_targets.html#multilabelbinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(sparse_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pltracks = mlb.fit_transform(pltracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally have a list of 21k playlists encoded with the 269k unique tracks.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pltracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Cosine similarity\n",
    "\n",
    "https://stackoverflow.com/a/27046041/8928529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sim = cosine_similarity(pltracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to do a matrix multiply for user-user similarity: score = sim * ratings\n",
    "\n",
    "https://stackoverflow.com/a/16754459/8928529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cast the similarity martrix into a compressed sparse row format so matrix multiplication doesn't explode the ram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sim = sparse.csr_matrix(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score = sparse.csr_matrix.dot(sim, pltracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a score matrix in the original dimentions that is 17% sparse.  With 973mil out of 5billion possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append Challenge Set to Training Set\n",
    "\n",
    "Read the data from the challenge set file and append the tracks to training tracks in prep for similarity comparison. Omit first 1000 tracks since this is the title only subtask. Their similarity is implicitly zero on all tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data using Python JSON module\n",
    "with open(testset,'r') as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten data\n",
    "challenge_playlists = pd.json_normalize(data, record_path=['playlists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[challenge_playlists[\"tracks\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chtracks = [d for d in challenge_playlists[[\"tracks\"]].tracks.apply((lambda s: [d[\"track_uri\"] for d in s]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chtracks[1002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltracks = [d for d in playlists[[\"tracks\"]].tracks.apply((lambda s: [d[\"track_uri\"] for d in s]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltracks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chtracks[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltracks = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltracks = pltracks + chtracks[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alltracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute cosine sim of challenge tracks\n",
    "\n",
    "The data set is combined with training and challenge to compute the missing track score, i.e. recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmpb = mlb.fit_transform(alltracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmpb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sim = cosine_similarity(allmpb, dense_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avoid int32 index bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = utils.convert_to_64bit_indices(sim)\n",
    "allmpb = utils.convert_to_64bit_indices(allmpb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory use in virt jumps from 15g to 30g in the next operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "score = sparse.csr_matrix.dot(sim, allmpb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manage memory by delete data we don't need after the score is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del allmpb\n",
    "del sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Top-N Tracks\n",
    "\n",
    "Use the global top-N tracks to backfill missing data for playlist recommendation.\n",
    "The top-n global also forms a baseline recommender to assess overall performance.\n",
    "\n",
    "We focus on the global track stats for the training dataset only. It makes sense because this is the known data but also because the final submission requires removal of challenge seed tracks so any track information learned from the challenge set can't be reused in the same list. Worth questioning some since it can't be reused in the same seed but could be in other playlists...\n",
    "\n",
    "However, do we need the full corpus so that we can match up the vocabulary terms to the tracks?  No because we can just use the Vecotrizors vocab.\n",
    "\n",
    "Approach is to treat the training playlists as corpus of text documents.  Count the occurance of terms with the count vectorizer.  Then sum the term counts into a single array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consruct corpus from playlists joined a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ \" \".join(doc) for doc in alltracks[0:2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a custom tokenizer to avoid splitting on the punctuation characters in the \"spotify:track:xxx' pattern. https://stackoverflow.com/a/37884104/8928529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackcounts = vectorizer.fit_transform([\" \".join(doc) for doc in alltracks[0:20000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.sparse.from_spmatrix(trackcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackfreq = trackcounts.T.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trackfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackfreq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(trackfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = [(\"trackidx\", int), (\"count\", int)]\n",
    "new = np.empty(len(trackfreq), dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([*range(len(trackfreq))]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['trackidx'] = np.array([*range(len(trackfreq))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(trackfreq).reshape(len(trackfreq)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['count'] = np.array(trackfreq).reshape(len(trackfreq))\n",
    "#print new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = zip(new[\"trackidx\"], new[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = sorted(tuples, key=lambda x: (x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invert the vocabulary dictionary so we can map it to the tracks. https://stackoverflow.com/a/483833/8928529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map = {v: k for k, v in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a list of the topn track identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toptracks=[inv_map[i] for i, cnt in iter(topn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toptracks = toptracks[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top tracks can now be appended to each list an ensure we have the minimum recommenadable track set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore filtering challenge tracks from recommendation list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the challenge tracks from the recommended set.\n",
    "Use a simple loop for now to keep the code simple.\n",
    "Also allows us to inspect where the original songs are in the recommendation set.\n",
    "For the current playlist, app positions for the first 5 songs are above the 500 song rec limit.\n",
    "This suggests we will see a fairly poor rprec and ndcg performance for pure user-user knn.\n",
    "Makes sense, since this is really just a most popular songs amoung similar users strategey.\n",
    "A user focused popularity ranking rather than a global popularity ranking.\n",
    "Suggests the need for the boosting strategies we see in the actually top performers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(rectracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the entire recommendation set. This is lists 21000-30000 in the currrent method. No index math is needed if we shift to putting the challenge tracks at the start.\n",
    "\n",
    "Trim the recommenation set out of the score results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with the del earlier the RES memory remains  at 28g which helps explain why the next step kills the kernel\n",
    "\n",
    "    98895 jpr       20   0   29.9g  28.7g  29564 S   0.0 15.3   4:06.54 python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with explicit garbage collection this doesn't free up the ram.\n",
    "\n",
    "https://stackoverflow.com/questions/1316767/how-can-i-explicitly-free-memory-in-python\n",
    "\n",
    "Advice is to use a subprocess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe it means I need to save out the results and reload them either in a new notebook or after the kernel barfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickle.dump(score, open( \"save_score.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score=pickle.load(open( \"save_score.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even pickle kills the kernel. \n",
    "Maybe best to just add some ram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = score[len(pltracks):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the challenge tracks from the recommendation list.  The recommendation list is augmented with the topn (n=1000) most popular tracks to backfill recommendations that don't have enough tracks to fill the 500 count requirement.\n",
    "\n",
    "The algorithm slows noticably as the number of challenge tracks increases and the recommendation list has to be search repeatedly.\n",
    "\n",
    "The 9000 scored playlists start for playlist 1000.\n",
    "The challenge playlist starts with the first playlist.\n",
    "Need to offset the challenge playlist index to match the score structure and recommended tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "import time\n",
    "\n",
    "reclist = list()\n",
    "indexdist = list() #pd.DataFrame(columns=[\"index\"])\n",
    "misses = 0\n",
    "tooshort = 0\n",
    "trace = False\n",
    "\n",
    "start_time = time.time()\n",
    "for idx in range(9000):\n",
    "    # get the candidate track class id sorted by recommendation score\n",
    "    cantracks = utils.sort_csr(score[idx])\n",
    "    # convert class id to spotify track name\n",
    "    rectracks=[mlb.classes_[i[0]] for i in cantracks]\n",
    "    # ensure mininum length recommendation meets 500 tracks requirement\n",
    "    rectracks=rectracks + toptracks\n",
    "    # truncate rectracks to top1000 to limit search effort for challenge tracks\n",
    "    rectracks=rectracks[:1000]\n",
    "    if (trace): print(\"idx {}:\".format(idx))\n",
    "    # remove challenge tracks from recommendation list\n",
    "    # note: the challenge tracks start at index 1000 to allign tasks with recommendations\n",
    "    \n",
    "    # convert to dataframe to benefit from vector operations\n",
    "    # impoves about 2x over speed of manual loops.\n",
    "    recdf = pd.DataFrame(rectracks, columns=[\"track\"])\n",
    "    filterlist = recdf[recdf.track.isin(chtracks[idx+1000])].index\n",
    "    # need to record index collection for distribution analysis but this isn't the correct approach\n",
    "    #indexdist.append(filterlist)\n",
    "    recdf.drop(filterlist, inplace=True )\n",
    "    rectracks = recdf[\"track\"].tolist()\n",
    "\n",
    "    #for challenge_track in chtracks[idx+1000]:\n",
    "    #    if (trace): print(\"look for track: {}\".format(challenge_track))\n",
    "    #    while challenge_track in rectracks:\n",
    "    #        try:\n",
    "    #            indexdist.append(rectracks.index(challenge_track))\n",
    "    #            if (trace): print(\"remove track pos: {}\".format(rectracks.index(challenge_track)))\n",
    "    #            rectracks.remove(challenge_track)\n",
    "    #        except (ValueError, AttributeError):\n",
    "    #            if (trace): print(\"didn't find in rectracks: {}\".format(challenge_track))\n",
    "    #            misses += 1\n",
    "\n",
    "    \n",
    "    #if reclist < 500:\n",
    "    #    tooshort += 1\n",
    "    \n",
    "    # truncate recommendation list to the 500 length required\n",
    "    reclist.append(rectracks[0:500])\n",
    "    \n",
    "    # progress bar\n",
    "    if (idx % 1000) == 0:\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(\"challenge tracks progress: {}\".format(idx))\n",
    "        start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index distribution is a simple peek into the performance of the KNN algorithm.  It shows the average index value of the seeded challenge tracks found in the recommendations.  Given that this number is dominated by values above the general playlist lengths and even above 500 it's clear that the similarity measure alone is not an effective way of organizing the recommendation results.\n",
    "\n",
    "Correction: the challenge set index was misalligned with the recommendation set index.  After updating the index to start after the title only task (+1000) the collection of matches shifted to where 70% of tracks were found in the first 500 recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indexdist = pd.DataFrame(indexdist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of removals shows that the vast majority are well above the 500 reclist limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indexdist.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reclist[8995])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(reclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add the top popular to flesh out recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toptracks[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldstart = pd.DataFrame(columns=[*range(500)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldstart = coldstart.append([toptracks[0:500]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# create data frame of 1000 copies of top popular to substitute for title only cold start recommendation\n",
    "\n",
    "coldstart = pd.DataFrame(columns=[*range(500)])\n",
    "\n",
    "for i in range(1000):\n",
    "    coldstart = coldstart.append([toptracks[0:500]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldstart.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = coldstart.append(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the index so all rows have a distinct index value.  This is necessary so the pid insert below correctly adds each pid to the title only task.  Otherwise the repeated rows of the task are seen as a single distinct row and all get the same pid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = solution.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add playlist id into the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[*range(10,10,1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate playlist ID value range to create correct submission format.  We don't want to use a naive range of ids like the following\n",
    "\n",
    "    pid = pd.DataFrame([*range(1000000,1010000)]) \n",
    "\n",
    "We want to use the original pids from the challenge set.\n",
    "The pid is not arbitrary and should match the order of the pid in the challenge_playlists.  \n",
    "The rows of the solution are in the order of the original challenge set to should apply directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = challenge_playlists[\"pid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid=pid.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.insert(0, \"pid\", pid) #[*range(2000000,2010000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution#[998:1005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write solution to output file\n",
    "\n",
    "Include only the data not any index or headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_csv = solution.to_csv(index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(challenge_solution, \"w\")\n",
    "n = text_file.write(challenge_header+solution_csv)\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
