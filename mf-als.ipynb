{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MF with ALS Collaborative Filtering\n",
    "\n",
    "Create a basic matrix factorization (MF) with alternating least squares (ALS) collaboritive filtering solution (mf-als) for recommended tracks. \n",
    "This is built from the Verstrepen2017 matrix notation of a score matrix factored by a user embedding and item embedding matrix.\n",
    "\n",
    "    Score = User-embedding x Item-embedding \n",
    "    \n",
    "This is implemented using the techniques [using the implicit library](https://towardsdatascience.com/alternating-least-square-for-implicit-dataset-with-code-8e7999277f4b).\n",
    "\n",
    "The matrix factorization is built from an append of the challenge set to the training set.\n",
    "This is required to ensure all playlists (pids, a.k.a. users) are represented in the model and it can be used to make recommendations for the \n",
    "\n",
    "The cold start task is address with a simple global popularity ranking of tracks.\n",
    "We compute the global popularity of tracks and recommend the first 500 in ranked order.\n",
    "This set is also included as backfill to each playlist recommendation accross all subtasks to ensure the minimum 500 tracks are available to each challenge solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters for Run\n",
    "\n",
    "These parameters control the selection of dataset, challenge set, and solution output.\n",
    "\n",
    "Must select dataset and challege_name.  The rest are derived parameters and can be left alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the directory with different collections of training and test sets\n",
    "datadir=\"data/\"  # path to base data set\n",
    "\n",
    "# select the data for training  \n",
    "#dataset=\"mpd/data\"     # the original full mpd training set, requires quick=True and max_files set\n",
    "#dataset=\"mpd-1st-21k\"  # first 21 files of mpd, equiv to quick=True and max_files 20\n",
    "#dataset=\"mpd-2nd-21k\"  # second 21 files of mpd, avoids using data that built mympd challenge set\n",
    "dataset=\"mympd-full-20k\"\n",
    "\n",
    "# select data for testing, this is the challenge_set.json file for specific challenge data\n",
    "#challenge_name=\"mpd\"  # original mpd challenge set, use with aicrowd\n",
    "#challenge_name=\"mympd\"  # my custom challenge set for task analysis\n",
    "challenge_name=\"mympd-full\"  # my custom challenge sampled from full training set for task analysis\n",
    "\n",
    "# derived parameters, no need to change.\n",
    "\n",
    "#trainset=\"data/mpd/data\"  # relative path to training set in slice json file format\n",
    "trainset=datadir+dataset+\"/data\"  # relative path to training set in slice json file format\n",
    "\n",
    "#testset=\"data/challenge_set.json\" # relative path to test set in challenge_set.json format\n",
    "#testset=datadir+challenge_name+\"-challenge-set/challenge_set.json\" # relative path to test set in challenge_set.json format\n",
    "testset=datadir+challenge_name+\"/challenge_set.json\" # relative path to test set in challenge_set.json format\n",
    "\n",
    "datestr=date.isoformat(date.today())\n",
    "\n",
    "challenge_header = \"team_info,jprorama,jprorama@gmail.com\\n\"\n",
    "challenge_solution = \"method-mfals-\"+challenge_name+\"-\"+dataset+\"-\"+datestr+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate more verbose output for some functions\n",
    "debug = True\n",
    "\n",
    "# parameters for mpd load, superceeded by mpd-1st-21k\n",
    "quick = False\n",
    "max_files_for_quick_processing = 20\n",
    "\n",
    "# random state\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the mpd slice files\n",
    "\n",
    "Create one big data frame to make it simple to select the random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = pd.DataFrame()\n",
    "tracks = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mpd(path):\n",
    "    global playlists, tracks;\n",
    "    \n",
    "    count = 0\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in sorted(filenames):\n",
    "        if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            if debug: print(\"loaded {}:\".format(fullpath))\n",
    "            mpd_slice = json.loads(js)\n",
    "            # Flatten data\n",
    "            # extract slice info to keep association with original training files.\n",
    "            slice_info = mpd_slice['info']['slice']\n",
    "            slice_playlists = pd.json_normalize(mpd_slice, record_path=['playlists'])\n",
    "            slice_playlists[\"slice\"] = slice_info\n",
    "            if debug: print(\"slice length {}:\".format(len(slice_playlists)))\n",
    "            slice_tracks = pd.json_normalize(mpd_slice['playlists'], record_path=['tracks'], meta=['pid'])\n",
    "            # drop tracks from playlist dataframe\n",
    "            # not worth it to save space, just makes it harder to reconstruct the playlist\n",
    "            #slice_playlists.drop(columns='tracks', inplace=True)\n",
    "            playlists = playlists.append(slice_playlists)\n",
    "            tracks = tracks.append(slice_tracks)\n",
    "            count += 1\n",
    "\n",
    "            if quick and count > max_files_for_quick_processing:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "process_mpd(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a new index for playlists so each row has unique id using pid. After reading the slice files the index values repeat for each slice.\n",
    "\n",
    "Preference is to not use the pid since that drops this data column.\n",
    "Instead create a new column of integers for each row and then set that as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[\"newidx\"]=range(len(playlists))\n",
    "\n",
    "playlists.set_index(\"newidx\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = playlists.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = playlists[[\"pid\",\"tracks\"]].explode(\"tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl[\"track_uri\"] = [d.get(\"track_uri\") for d in pl.tracks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl[\"artist_name\"] = [d.get(\"artist_name\") for d in pl.tracks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expanded one-row-per-track representation shows we have 1.4million songs (rows). The row index has 21k entries which matches the 21k playlists in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pl[[\"track_uri\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From example in [pandas sparse data types page](https://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html) use memory_usage().sum().  Not clear why we divide by 1000.  Would think that makes it kilobytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'dense : {:0.2f} kbytes'.format(tracks.memory_usage().sum() / 1e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot encode playlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to use get_dummies() works in the dense space an tries to build a dataframe of 100k by 1.4Million songs.  Not sure why so many rows but it's still to big for ram at 300+G\n",
    "\n",
    "trackhots = pd.get_dummies(tracks, dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn has a onehot encoder that is a preprocessor to many of its routines.  See if we can fit the tracks to this representaiton.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl[[\"pid\", \"track_uri\"]].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackhots = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackhots.fit(pl[[\"pid\", \"track_uri\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackhots.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackhots.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the original data into a matrix representation.\n",
    "\n",
    "Here again is the 1.4x290k represenation.  The 1.4k is the songs, so rows in the original matrix but not clear where the 290k comes from.  Would expect 21k for the playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = trackhots.transform(pl[[\"pid\",\"track_uri\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl[\"pid\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[\"num_tracks\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, there are some problems in the transformation.  The 1.4mil comes from the total number of tracks in training.  The total unique is much smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl[\"track_uri\"].drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd expect an transformed data set to be 21k by 269k.\n",
    "\n",
    "Ah, the onehot encoder wants a feature set of each record with its distinct features.\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features\n",
    "\n",
    "in this case it's rows of track_uri.\n",
    "so each row with mapp to the idx value and will just have tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl[[\"track_uri\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try converting each tracks string to a data type \n",
    "\n",
    "https://www.geeksforgeeks.org/python-convert-string-dictionary-to-dictionary/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[[\"tracks\"]].tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a list of lists. This is pretty easy to construct with a list comprehension to wrap the lists into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltracks = [d for d in playlists[[\"tracks\"]].tracks.apply((lambda s: [d[\"track_uri\"] for d in s]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pltracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pltracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what we are really trying to do is train the encoding and then transform each row.\n",
    "\n",
    "this is more like having a vocabulary and different sentances.\n",
    "I need to map each sentance to it's onehot encoding of the vocabulary.\n",
    "\n",
    "this example shows moving from an integerencoding to a one hot encoding\n",
    "https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "\n",
    "reading the docs leads to multi label binarizer which appears to be closer to what i want.\n",
    "https://scikit-learn.org/stable/modules/preprocessing_targets.html#multilabelbinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(sparse_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltracks = mlb.fit_transform(pltracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally have a list of 21k playlists encoded with the 269k unique tracks.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append Challenge Set to Training Set\n",
    "\n",
    "Read the data from the challenge set file and append the tracks to training tracks in prep for similarity comparison. Omit first 1000 tracks since this is the title only subtask. Their similarity is implicitly zero on all tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data using Python JSON module\n",
    "with open(testset,'r') as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten data\n",
    "challenge_playlists = pd.json_normalize(data, record_path=['playlists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[challenge_playlists[\"tracks\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chtracks = [d for d in challenge_playlists[[\"tracks\"]].tracks.apply((lambda s: [d[\"track_uri\"] for d in s]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chtracks[1002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltracks = [d for d in playlists[[\"tracks\"]].tracks.apply((lambda s: [d[\"track_uri\"] for d in s]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltracks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chtracks[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltracks = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltracks = pltracks + chtracks[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alltracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MF of train and challenge tracks\n",
    "\n",
    "The data set is combined with training and challenge to compute the missing track score, i.e. recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmpb = mlb.fit_transform(alltracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmpb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the hyper parameters from Volksov2018.\n",
    "\"we found that using rank 200 with α = 100 and λU = λV = 0.001 produced good performance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale all binary indicators by 100 to introduce the confidence weight of\n",
    "\n",
    "c_ui=1+\\alpha(R_ij)\n",
    "\n",
    "This multiplcation aproach doesn't seem to get the 1 in place so not clear how ALS compute i the library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmpb_weighted = allmpb.multiply(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmpb_weighted = allmpb.multiply(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a model\n",
    "model = implicit.als.AlternatingLeastSquares(factors=200, regularization=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(allmpb_weighted.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend items for a user\n",
    "#user_items = item_user_data.T.tocsr()\n",
    "recommendations = model.recommend(21000, allmpb, N=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[id for id, score in model.recommend(21000, allmpb, N=500)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore sorting by score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from itertools import izip\n",
    "\n",
    "def sort_csr(m):\n",
    "    tuples = zip(m.indices, m.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1]), reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Top-N Tracks\n",
    "\n",
    "Use the global top-N tracks to backfill missing data for playlist recommendation.\n",
    "The top-n global also forms a baseline recommender to assess overall performance.\n",
    "\n",
    "We focus on the global track stats for the training dataset only. It makes sense because this is the known data but also because the final submission requires removal of challenge seed tracks so any track information learned from the challenge set can't be reused in the same list. Worth questioning some since it can't be reused in the same seed but could be in other playlists...\n",
    "\n",
    "However, do we need the full corpus so that we can match up the vocabulary terms to the tracks?  No because we can just use the Vecotrizors vocab.\n",
    "\n",
    "Approach is to treat the training playlists as corpus of text documents.  Count the occurance of terms with the count vectorizer.  Then sum the term counts into a single array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consruct corpus from playlists joined a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ \" \".join(doc) for doc in alltracks[0:2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a custom tokenizer to avoid splitting on the punctuation characters in the \"spotify:track:xxx' pattern. https://stackoverflow.com/a/37884104/8928529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackcounts = vectorizer.fit_transform([\" \".join(doc) for doc in alltracks[0:20000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.sparse.from_spmatrix(trackcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackfreq = trackcounts.T.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trackfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackfreq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(trackfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = [(\"trackidx\", int), (\"count\", int)]\n",
    "new = np.empty(len(trackfreq), dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([*range(len(trackfreq))]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['trackidx'] = np.array([*range(len(trackfreq))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(trackfreq).reshape(len(trackfreq)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['count'] = np.array(trackfreq).reshape(len(trackfreq))\n",
    "#print new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = zip(new[\"trackidx\"], new[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = sorted(tuples, key=lambda x: (x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invert the vocabulary dictionary so we can map it to the tracks. https://stackoverflow.com/a/483833/8928529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map = {v: k for k, v in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a list of the topn track identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toptracks=[inv_map[i] for i, cnt in iter(topn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toptracks = toptracks[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top tracks can now be appended to each list an ensure we have the minimum recommenadable track set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore filtering challenge tracks from recommendation list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the challenge tracks from the recommendation list.  The recommendation list is augmented with the topn (n=1000) most popular tracks to backfill recommendations that don't have enough tracks to fill the 500 count requirement.\n",
    "\n",
    "The algorithm slows noticably as the number of challenge tracks increases and the recommendation list has to be search repeatedly.\n",
    "\n",
    "The 9000 scored playlists start for playlist 1000.\n",
    "The challenge playlist starts with the first playlist.\n",
    "Need to offset the challenge playlist index to match the score structure and recommended tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reclist = list()\n",
    "indexdist = list() #pd.DataFrame(columns=[\"index\"])\n",
    "misses = 0\n",
    "tooshort = 0\n",
    "trace = False\n",
    "\n",
    "for idx in range(9000):\n",
    "    # get the candidate track class id sorted by recommendation score\n",
    "    cantracks = model.recommend(idx+21000, allmpb, N=500) # [id for id, score in model.recommend(idx, allmpb, N=500)]\n",
    "    # convert class id to spotify track name\n",
    "    rectracks=[mlb.classes_[i[0]] for i in cantracks]\n",
    "    # ensure mininum length recommendation meets 500 tracks requirement\n",
    "    rectracks=rectracks + toptracks\n",
    "    if (trace): print(\"idx {}:\".format(idx))\n",
    "    # remove challenge tracks from recommendation list\n",
    "    # note: the challenge tracks start at index 1000 to allign tasks with recommendations\n",
    "    for challenge_track in chtracks[idx+1000]:\n",
    "        if (trace): print(\"look for track: {}\".format(challenge_track))\n",
    "        while challenge_track in rectracks:\n",
    "            try:\n",
    "                indexdist.append(rectracks.index(challenge_track))\n",
    "                if (trace): print(\"remove track pos: {}\".format(rectracks.index(challenge_track)))\n",
    "                rectracks.remove(challenge_track)\n",
    "            except (ValueError, AttributeError):\n",
    "                if (trace): print(\"didn't find in rectracks: {}\".format(challenge_track))\n",
    "                misses += 1\n",
    "    #if reclist < 500:\n",
    "    #    tooshort += 1\n",
    "    \n",
    "    # truncate recommendation list to the 500 length required\n",
    "    reclist.append(rectracks[0:500])\n",
    "    \n",
    "    # progress bar\n",
    "    if (idx % 1000) == 0: print(\"challenge tracks progress: {}\".format(idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index distribution is a simple peek into the performance of the KNN algorithm.  It shows the average index value of the seeded challenge tracks found in the recommendations.  Given that this number is dominated by values above the general playlist lengths and even above 500 it's clear that the similarity measure alone is not an effective way of organizing the recommendation results.\n",
    "\n",
    "Correction: the challenge set index was misalligned with the recommendation set index.  After updating the index to start after the title only task (+1000) the collection of matches shifted to where 70% of tracks were found in the first 500 recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indexdist = pd.DataFrame(indexdist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of removals shows that the vast majority are well above the 500 reclist limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indexdist.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reclist[8995])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(reclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add the top popular to flesh out recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toptracks[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldstart = pd.DataFrame(columns=[*range(500)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldstart = coldstart.append([toptracks[0:500]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frame of 1000 copies of top popular to substitute for title only cold start recommendation\n",
    "\n",
    "coldstart = pd.DataFrame(columns=[*range(500)])\n",
    "\n",
    "for i in range(1000):\n",
    "    coldstart = coldstart.append([toptracks[0:500]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldstart.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = coldstart.append(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the index so all rows have a distinct index value.  This is necessary so the pid insert below correctly adds each pid to the title only task.  Otherwise the repeated rows of the task are seen as a single distinct row and all get the same pid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = solution.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add playlist id into the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[*range(10,10,1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate playlist ID value range to create correct submission format.  We don't want to use a naive range of ids like the following\n",
    "\n",
    "    pid = pd.DataFrame([*range(1000000,1010000)]) \n",
    "\n",
    "We want to use the original pids from the challenge set.\n",
    "The pid is not arbitrary and should match the order of the pid in the challenge_playlists.  \n",
    "The rows of the solution are in the order of the original challenge set to should apply directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = challenge_playlists[\"pid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid=pid.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.insert(0, \"pid\", pid) #[*range(2000000,2010000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution#[998:1005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write solution to output file\n",
    "\n",
    "Include only the data not any index or headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_csv = solution.to_csv(index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(challenge_solution, \"w\")\n",
    "n = text_file.write(challenge_header+solution_csv)\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
