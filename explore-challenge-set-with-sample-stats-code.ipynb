{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the distribution of playlist data attributes in the recsys18 challenge dataset.\n",
    "\n",
    "Need to know what the profile of unknown playlists are so we can build a representantive dataset \n",
    "from the MPD training set.\n",
    "\n",
    "The challenge data set is 10x1000 playslists.\n",
    "There is no info header describing the file as in the mpd slice files, just the playlist dictionary.\n",
    "Each playlist has a tracks dictionary that may be empty.\n",
    "Each playlist has a 'num_samples: \"x\"' parameter where x is 0,5,10,25,100 to match the challenge category.\n",
    "For the title-only playists 'num_samples: \"0\"' and there are no tracks in tracks dictionary.\n",
    "For the title a no-title variations there is either a title attribute or there is not.\n",
    "The num_samples + num_holdouts = num_tracks, which is the lenght of the orignal playlist.\n",
    "The track entries lists tracks as in the original mpd data set and includes position.\n",
    "Position is always 0 through num_samples-1 for the sequential seeds.\n",
    "Position appears to be 0 through num_tracks with some number of drop-outs for the random samples.\n",
    "That is, the sampling appears to drop out the tracks throughout the playlist.\n",
    "This means the recommenders should have a rich embedding and are just filling in small holes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_playlists = 0\n",
    "total_tracks = 0\n",
    "tracks = set()\n",
    "artists = set()\n",
    "albums = set()\n",
    "titles = set()\n",
    "total_descriptions = 0\n",
    "ntitles = set()\n",
    "title_histogram = collections.Counter()\n",
    "artist_histogram = collections.Counter()\n",
    "track_histogram = collections.Counter()\n",
    "last_modified_histogram = collections.Counter()\n",
    "num_edits_histogram = collections.Counter()\n",
    "playlist_length_histogram = collections.Counter()\n",
    "num_followers_histogram = collections.Counter()\n",
    "\n",
    "quick = False\n",
    "max_files_for_quick_processing = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mpd(path):\n",
    "    count = 0\n",
    "    playlist_count = 0\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in sorted(filenames):\n",
    "        #if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "        if filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            mpd_slice = json.loads(js)\n",
    "            #process_info(mpd_slice['info'])\n",
    "            for playlist in mpd_slice['playlists']:\n",
    "                process_playlist(playlist)\n",
    "                playlist_count += 1\n",
    "                if ((playlist_count % 1000) == 0):\n",
    "                    print(\"============================\")\n",
    "                    print(\"challenge subset {}\".format(count % 1000))\n",
    "                    show_summary()\n",
    "                    print(\"============================\")\n",
    "                    reset_stats()                \n",
    "            count += 1\n",
    "\n",
    "            if quick and count > max_files_for_quick_processing:\n",
    "                break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_stats():\n",
    "    \n",
    "    global total_playlists\n",
    "    global total_tracks\n",
    "    global tracks\n",
    "    global artists\n",
    "    global albums\n",
    "    global titles\n",
    "    global total_descriptions\n",
    "    global ntitles\n",
    "    global title_histogram\n",
    "    global artist_histogram\n",
    "    global track_histogram\n",
    "    global last_modified_histogram\n",
    "    global num_edits_histogram\n",
    "    global playlist_length_histogram\n",
    "    global num_followers_histogram\n",
    "    \n",
    "    total_playlists = 0\n",
    "    total_tracks = 0\n",
    "    tracks = set()\n",
    "    artists = set()\n",
    "    albums = set()\n",
    "    titles = set()\n",
    "    total_descriptions = 0\n",
    "    ntitles = set()\n",
    "    title_histogram = collections.Counter()\n",
    "    artist_histogram = collections.Counter()\n",
    "    track_histogram = collections.Counter()\n",
    "    last_modified_histogram = collections.Counter()\n",
    "    num_edits_histogram = collections.Counter()\n",
    "    playlist_length_histogram = collections.Counter()\n",
    "    num_followers_histogram = collections.Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_playlist(playlist):\n",
    "    global total_playlists, total_tracks, total_descriptions\n",
    "\n",
    "    total_playlists += 1\n",
    "    # print playlist['playlist_id'], playlist['name']\n",
    "\n",
    "    if 'description' in playlist:\n",
    "        total_descriptions += 1\n",
    "\n",
    "    try:\n",
    "        playlist['name']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    else:\n",
    "        titles.add(playlist['name'])\n",
    "        nname = normalize_name(playlist['name'])\n",
    "        ntitles.add(nname)\n",
    "        title_histogram[nname] += 1\n",
    "\n",
    "    playlist_length_histogram[playlist['num_tracks']] += 1\n",
    "    #last_modified_histogram[playlist['modified_at']] += 1\n",
    "    #num_edits_histogram[playlist['num_edits']] += 1\n",
    "    #num_followers_histogram[playlist['num_followers']] += 1\n",
    "\n",
    "    for track in playlist['tracks']:\n",
    "        total_tracks += 1\n",
    "        albums.add(track['album_uri'])\n",
    "        tracks.add(track['track_uri'])\n",
    "        artists.add(track['artist_uri'])\n",
    "\n",
    "        full_name = track['track_name'] + \" by \" + track['artist_name']\n",
    "        artist_histogram[track['artist_name']] += 1\n",
    "        track_histogram[full_name] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_info(_):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_name(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[.,\\/#!$%\\^\\*;:{}=\\_`~()@]\", ' ', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name\n",
    "\n",
    "\n",
    "def to_date(epoch):\n",
    "    return datetime.datetime.fromtimestamp(epoch).strftime(\"%Y-%m-%d\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_summary():\n",
    "    print()\n",
    "    print(\"number of playlists\", total_playlists)\n",
    "    print(\"number of tracks\", total_tracks)\n",
    "    print(\"number of unique tracks\", len(tracks))\n",
    "    print(\"number of unique albums\", len(albums))\n",
    "    print(\"number of unique artists\", len(artists))\n",
    "    print(\"number of unique titles\", len(titles))\n",
    "    print(\"number of playlists with descriptions\", total_descriptions)\n",
    "    print(\"number of unique normalized titles\", len(ntitles))\n",
    "    print(\"avg playlist length\", float(total_tracks) / total_playlists)\n",
    "    print()\n",
    "    print(\"top playlist titles\")\n",
    "    for title, count in title_histogram.most_common(20):\n",
    "        print(\"%7d %s\" % (count, title))\n",
    "\n",
    "    print()\n",
    "    print(\"top tracks\")\n",
    "    for track, count in track_histogram.most_common(20):\n",
    "        print(\"%7d %s\" % (count, track))\n",
    "\n",
    "    print()\n",
    "    print(\"top artists\")\n",
    "    for artist, count in artist_histogram.most_common(20):\n",
    "        print(\"%7d %s\" % (count, artist))\n",
    "\n",
    "    print()\n",
    "    print(\"numedits histogram\")\n",
    "    for num_edits, count in num_edits_histogram.most_common(20):\n",
    "        print(\"%7d %d\" % (count, num_edits))\n",
    "\n",
    "    print()\n",
    "    print(\"last modified histogram\")\n",
    "    for ts, count in last_modified_histogram.most_common(20):\n",
    "        print(\"%7d %s\" % (count, to_date(ts)))\n",
    "\n",
    "    print()\n",
    "    print(\"playlist length histogram\")\n",
    "    for length, count in playlist_length_histogram.most_common(20):\n",
    "        print(\"%7d %d\" % (count, length))\n",
    "\n",
    "    print()\n",
    "    print(\"num followers histogram\")\n",
    "    for followers, count in num_followers_histogram.most_common(20):\n",
    "        print(\"%7d %d\" % (count, followers))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_stats()\n",
    "process_mpd(\"./data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above processing is not very useful because i have to create new code for each statistic to gather. It would be better to have a data structure to query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Pandas to Explore Challenge Structure\n",
    "\n",
    "Pandas provides lots convenience routines and data frame that is easily constructed and queried.\n",
    "\n",
    "Follow this recipe to load the data and split the results into a table for playlists and tracks.\n",
    "https://towardsdatascience.com/how-to-convert-json-into-a-pandas-dataframe-100b2ae1e0d8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data using Python JSON module\n",
    "with open('data/challenge_set.json','r') as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten data\n",
    "playlists = pd.json_normalize(data, record_path=['playlists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.json_normalize(data['playlists'], record_path=['tracks'], meta=['pid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather stats on each challenge subtype\n",
    "\n",
    "### Title Only\n",
    "\n",
    "The source playlist lenth of the title only seeds range from 10-50 tracks, with each length represented fairly evenly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[0:1000].hist( column=\"num_tracks\", bins=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[0:1000].num_tracks.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(playlists[0:1000].num_tracks.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(playlists[0:999].num_tracks.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.sort(playlists[0:1000].num_tracks.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histvals = playlists[0:1000].num_tracks.value_counts(bins=40) #.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histvals.hist(bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Seed with Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[1000:1001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[1000:2000].hist( column=\"num_tracks\", bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[1000:2000].num_tracks.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Seed without Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[2000:2001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[2000:3000].hist( column=\"num_tracks\", bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[2000:3000].num_tracks.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Seed with Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[3000:3001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[3000:4000].hist( column=\"num_tracks\", bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Seed without Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[4000:4001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[4000:5000].hist( column=\"num_tracks\", bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25 Seed with Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[5000:5001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[tracks.pid == 1000001].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[5000:6000].hist( column=\"num_tracks\", bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25 Rand with Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[6000:6001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[tracks.pid == 1007147].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[6000:7000].hist( column=\"num_tracks\", bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 Seed with Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[7000:7001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[tracks.pid == 1010382].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[7000:8000].hist( column=\"num_tracks\", bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 Rand with Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[8000:8001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[tracks.pid == 1018569].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[8000:8999].hist( column=\"num_tracks\", bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Seed with Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[9000:9001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[9000:9999].hist( column=\"num_tracks\", bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[9000:9999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total num_tracks distribution across all challenge playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[0:10000].hist( column=\"num_tracks\", bins=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(playlists[0:10000].num_tracks.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.sort(playlists[0:10000].num_tracks.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[0:10000].num_tracks.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "- the distribution for 0-seed, 5-seed-title, and 1-seed are all unique.\n",
    "- the distribution for 5-notitle, 10-seed, and 10-notitle are roughly the same.\n",
    "- the distribution for 25-seed and 25-rand are the same\n",
    "- the distribution for 100-seed and 100-rand are the same\n",
    "\n",
    "need to show the histograms in a 5x2 image plot.\n",
    "\n",
    "but i can use these counts and the range of min max playlists in each of categories to select random playlists.\n",
    "\n",
    "rather than making this super difficult I could just sum up all the distributions and select an equivalent count for each num_tracks.\n",
    "then i can split those up according to the distribution overall.\n",
    "\n",
    "can also compare how the challenge distribution compares to the entire mpd.\n",
    "\n",
    "now that i have the challenge data set analyzed need to get back to parsing the full mpd.\n",
    "how best to pull out my 10k test set from the 1mil list?\n",
    "\n",
    "I can select the random filter method i used before to get a much smaller training set.\n",
    "but this is a bit different, i want to keep selecting random from the values that appear in the challenge set.\n",
    "\n",
    "looking at the unique num_tracks, each num_tracks from 10-250 is represented.\n",
    "just at different selection densities.\n",
    "so if i just randomly select according to the count of the distribution i should be good.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
