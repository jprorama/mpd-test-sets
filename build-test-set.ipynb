{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a test and training split for the mpd.\n",
    "\n",
    "Build a test data set from the mpd using the playlist distribution found in the official challenge set.\n",
    "\n",
    "This extracts 10k playlists from the mpd as a test set substitution for the original challenge set.  It saves the original mpd data files as a new training set with the test set removed. Keeping the structure of the original file set will simplify operation of codes that expect that input.\n",
    "\n",
    "The constructed splits will be named by a directory like mpd-split-<description> that contains the test-set.json and a data subdir with the mpd slices.\n",
    "    \n",
    "The challenge set will then need to be constructed from the test-set.json so that codes can processes a challenge set of withheld data. Additional downstream processing with rate results submitted against the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the mpd slice files\n",
    "\n",
    "Create one big data frame to make it simple to select the random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = pd.DataFrame()\n",
    "tracks = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "quick = True\n",
    "max_files_for_quick_processing = 20\n",
    "\n",
    "# random state\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mpd(path):\n",
    "    global playlists, tracks;\n",
    "    \n",
    "    count = 0\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in sorted(filenames):\n",
    "        if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            if debug: print(\"loaded {}:\".format(fullpath))\n",
    "            mpd_slice = json.loads(js)\n",
    "            # Flatten data\n",
    "            # extract slice info to keep association with original training files.\n",
    "            slice_info = mpd_slice['info']['slice']\n",
    "            slice_playlists = pd.json_normalize(mpd_slice, record_path=['playlists'])\n",
    "            slice_playlists[\"slice\"] = slice_info\n",
    "            if debug: print(\"slice length {}:\".format(len(slice_playlists)))\n",
    "            slice_tracks = pd.json_normalize(mpd_slice['playlists'], record_path=['tracks'], meta=['pid'])\n",
    "            # drop tracks from playlist dataframe\n",
    "            # not worth it to save space, just makes it harder to reconstruct the playlist\n",
    "            #slice_playlists.drop(columns='tracks', inplace=True)\n",
    "            playlists = playlists.append(slice_playlists)\n",
    "            tracks = tracks.append(slice_tracks)\n",
    "            count += 1\n",
    "\n",
    "            if quick and count > max_files_for_quick_processing:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "process_mpd(\"data/mpd/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a new index for playlists so each row has unique id using pid. After reading the slice files the index values repeat for each slice.\n",
    "\n",
    "Preference is to not use the pid since that drops this data column.\n",
    "Instead create a new column of integers for each row and then set that as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[\"newidx\"]=range(len(playlists))\n",
    "\n",
    "playlists.set_index(\"newidx\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Challenge set distribution\n",
    "\n",
    "Just read the data distribution from the challenge set file directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data using Python JSON module\n",
    "with open('data/challenge_set.json','r') as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten data\n",
    "challenge_playlists = pd.json_normalize(data, record_path=['playlists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists.drop(columns=['tracks'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists.num_tracks.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for length, count in challenge_playlists.num_tracks.value_counts().iteritems():\n",
    "    print(\"len {} count {}\".format(length,count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare distributions between challenge and train data set\n",
    "\n",
    "Can see that the challenge set is similar but has some boosted representation at the higher and lower ends, likely to accomidate the 4x use of 25 and 100 length playlists. and 2x use of 0,1,5 seed.\n",
    "\n",
    "The spikes in the mpd might be due to the natural boundaries people see as playlist length at 50+ 100+ and 150+ or maybe there was some defacto limit imposed by spotify for a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists.hist( column=\"num_tracks\", bins=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists.hist( column=\"num_tracks\", bins=240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract test set from training based on challenge distribution\n",
    "\n",
    "Sampling without replacement is implicit because the sample is taken from explicit playlist length subsets of the whole data set.\n",
    "This prevents resampling of the same playlist across different calls to sample.\n",
    "\n",
    "Could remove the sampled playlists from the original data set as we go along.\n",
    "This wouldn't change the sample behavior because it is already occuring on filtered playlist length and then sampling from that subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pd.DataFrame()\n",
    "\n",
    "for length, count in challenge_playlists.num_tracks.value_counts().iteritems():\n",
    "    if debug: print(\"len {} count {}\".format(length,count))\n",
    "    # shrink count by 10% of available tracks if there aren't enough\n",
    "    # should only happen during dev when full data set not in use\n",
    "    num_avail = len(playlists[playlists.num_tracks==length])\n",
    "    if (num_avail < count):\n",
    "        newcount=num_avail - int(num_avail * .10)\n",
    "        print(\"WARNING: adjusted len {} count from {} to {}\".format(length, count, newcount))\n",
    "        count=newcount\n",
    "    testset=testset.append(playlists[playlists.num_tracks==length].sample(n=count, random_state=seed))\n",
    "    #if debug: print(\"len(testset): {}\".format(len(testset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.hist( column=\"num_tracks\", bins=240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save test set as json\n",
    "\n",
    "Need to pull out the playlists in the test set and build a challenge set. \n",
    "Need to remove the rows from the training set that are now for testing only.\n",
    "Then build the training set without the test set.\n",
    "Each file needs a header.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testname=\"ex2-from-21k-train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today=datetime.datetime.now(datetime.timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(today.isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"data/\"+testname)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the info header\n",
    "testset.drop(columns=['slice'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a custom info header\n",
    "fileinfo = '''{{\n",
    "    \"info\": {{\n",
    "       \"generated_on\": \"{}\", \n",
    "       \"slice\": \"{}\", \n",
    "       \"version\": \"v1\"\n",
    "    }},\\n'''.format(today.isoformat(), testname) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testjson = testset.to_json(orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add extra indent to the json so it fits into the final output\n",
    "testjson = re.sub('\\n', '\\n    ', testjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/'+testname+'/testset.json','w') as f:\n",
    "    f.write(fileinfo + '    \"playlists\": ' + testjson)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove test set from training data\n",
    "\n",
    "Removing the sampled set of play lists is easy with the [isin() filter](https://stackoverflow.com/a/27965417/8928529).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm isin() filter removes correct count of testset playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[~playlists.pid.isin(testset.pid)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists.shape[0]-testset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = playlists[~playlists.pid.isin(testset.pid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the new training set\n",
    "\n",
    "Saving the data sets will be easy by just using the slice information to recreate the files and then adding the fileinfo header as above with slice and potentially version info named for test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainset[trainset.slice.isin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"data/\"+testname+\"/data\")\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for slice in trainset.slice.unique():\n",
    "    fileinfo = '''{{\n",
    "    \"info\": {{\n",
    "       \"generated_on\": \"{}\", \n",
    "       \"slice\": \"{}\", \n",
    "       \"version\": \"v1\"\n",
    "    }},\\n'''.format(today.isoformat(), slice) \n",
    "\n",
    "    trainjson = trainset[trainset.slice == slice].to_json(orient=\"records\", indent=4)\n",
    "    # add extra indent to the json so it fits into the final output\n",
    "    trainjson = re.sub('\\n', '\\n    ', trainjson)\n",
    "    slicefile = 'data/'+testname+'/data/mpd.slice.'+slice+'.json'\n",
    "    with open(slicefile,'w') as f:\n",
    "        f.write(fileinfo + '    \"playlists\": ' + trainjson)\n",
    "    f.close()\n",
    "    if debug: print(\"wrote slice {}\".format(slice))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test and training sets have now been created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create challenge data\n",
    "\n",
    "For each challenge set of 1000 tracks in the reference data:\n",
    "  * loop through the subset\n",
    "    * get a track of the requested length and remove it from the testset\n",
    "    * save testable format of pid and actual trackids in order\n",
    "    * format dropout it according to the challenge task\n",
    "    * add it to the challenge set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists[1000:2000].num_tracks.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the challenge set organization from the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_challenge=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testin = testset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a new unique test set index to accomidate oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testin[\"newidx\"]=range(len(testin))\n",
    "testin.set_index(\"newidx\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task(distribution, srcdata, trace=False):\n",
    "    '''\n",
    "    create a named challenge task from srcdata using the track length distribution\n",
    "    \n",
    "    the samples are removed from srcdata to implement without replacement across calls\n",
    "    '''\n",
    "    subset = pd.DataFrame()\n",
    "\n",
    "    for i, length in distribution.num_tracks.iteritems():\n",
    "        if trace: print(\"playlist: {} len: {}\".format(i, length))\n",
    "        #\n",
    "        # if we don't have enough input data re-use the last sample\n",
    "        # won't work if the first sample errors out.\n",
    "        #\n",
    "        try:\n",
    "            sample = srcdata[srcdata.num_tracks==length].sample(n=1, random_state=seed)\n",
    "            newsample=True\n",
    "        except ValueError:\n",
    "            if 'sample' not in locals():\n",
    "                print (\"ERROR: no first sample taking min matching sample outside of distribution\")\n",
    "                # pick a sample that is at least as long as the one in the distribution\n",
    "                sample=srcdata[srcdata.num_tracks>length].sample(n=1, random_state=seed)\n",
    "                last_sample = sample\n",
    "                #break\n",
    "            else:\n",
    "                if debug: print(\"WARNING: Playlist length {} not found reuse sample {}\".format(length, sample.pid))\n",
    "                sample = last_sample\n",
    "            newsample=False\n",
    "        subset = subset.append(sample)\n",
    "        if (newsample):\n",
    "            srcdata.drop(sample.index, inplace=True)\n",
    "            last_sample=sample\n",
    "        \n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_task_descriptor(dataset, name, num_samples, random, with_title):\n",
    "    '''\n",
    "    Add columns to challenge task describing the task. \n",
    "    This will help automate processing\n",
    "    '''\n",
    "    \n",
    "    dataset[\"task_name\"]=name\n",
    "    dataset[\"num_samples\"]=num_samples\n",
    "    dataset[\"random\"]=random\n",
    "    dataset[\"with_title\"]=with_title\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build title only task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists[0:1000].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_playlists = create_task(challenge_playlists[0:1000], testin)\n",
    "\n",
    "task_playlists = add_task_descriptor(task_playlists, name=\"title_only\", \n",
    "                                     num_samples=0, random=False, with_title=True)\n",
    "\n",
    "test_challenge=test_challenge.append(task_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Sample 5 with Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists[1000:2000].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_playlists = create_task(challenge_playlists[1000:2000], testin)\n",
    "\n",
    "task_playlists = add_task_descriptor(task_playlists, name=\"first_5_title\", \n",
    "                                     num_samples=5, random=False, with_title=True)\n",
    "\n",
    "test_challenge=test_challenge.append(task_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build First 5 without Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists[2000:3000].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_playlists = create_task(challenge_playlists[2000:3000], testin)\n",
    "\n",
    "task_playlists = add_task_descriptor(task_playlists, name=\"first_5_wo_title\", \n",
    "                                     num_samples=5, random=False, with_title=False)\n",
    "\n",
    "test_challenge=test_challenge.append(task_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build First 10 with Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists[3000:4000].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_playlists = create_task(challenge_playlists[3000:4000], testin)\n",
    "\n",
    "task_playlists = add_task_descriptor(task_playlists, name=\"first_10_title\", \n",
    "                                     num_samples=10, random=False, with_title=True)\n",
    "\n",
    "test_challenge=test_challenge.append(task_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build First 10 without Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists[4000:5000].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_playlists = create_task(challenge_playlists[4000:5000], testin)\n",
    "\n",
    "task_playlists = add_task_descriptor(task_playlists, name=\"first_10_wo_title\", \n",
    "                                     num_samples=10, random=False, with_title=False)\n",
    "\n",
    "test_challenge=test_challenge.append(task_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Rand 25 with Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists[5000:6000].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_playlists = create_task(challenge_playlists[5000:6000], testin)\n",
    "\n",
    "task_playlists = add_task_descriptor(task_playlists, name=\"first_25_title\", \n",
    "                                     num_samples=25, random=False, with_title=True)\n",
    "\n",
    "test_challenge=test_challenge.append(task_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Rand 25 without Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists[6000:7000].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_playlists = create_task(challenge_playlists[6000:7000], testin)\n",
    "\n",
    "task_playlists = add_task_descriptor(task_playlists, name=\"rand_25_title\", \n",
    "                                     num_samples=25, random=True, with_title=True)\n",
    "\n",
    "test_challenge=test_challenge.append(task_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Rand 100  with Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists[7000:8000].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_playlists = create_task(challenge_playlists[7000:8000], testin)\n",
    "\n",
    "task_playlists = add_task_descriptor(task_playlists, name=\"first_100_title\", \n",
    "                                     num_samples=100, random=False, with_title=True)\n",
    "\n",
    "test_challenge=test_challenge.append(task_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Rand 100 without Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists[8000:9000].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_playlists = create_task(challenge_playlists[8000:9000], testin)\n",
    "\n",
    "task_playlists = add_task_descriptor(task_playlists, name=\"rand_100_title\", \n",
    "                                     num_samples=100, random=True, with_title=True)\n",
    "\n",
    "test_challenge=test_challenge.append(task_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build First 1 with Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists[9000:10000].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_playlists = create_task(challenge_playlists[9000:10000], testin)\n",
    "\n",
    "task_playlists = add_task_descriptor(task_playlists, name=\"first_1_title\", \n",
    "                                     num_samples=1, random=False, with_title=True)\n",
    "\n",
    "test_challenge=test_challenge.append(task_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All testset entries have been consumed and every task has been populated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write challenge set \n",
    "\n",
    "This is the answer key for the corresponding testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_set(dataset, datasetname, timestamp, name=\"challengeset.json\", tag=\"\"): \n",
    "    '''Save dataframe to json format following MPD format convention with header'''\n",
    "\n",
    "    # add a custom info header\n",
    "    fileinfo = '''{{\n",
    "        \"info\": {{\n",
    "           \"generated_on\": \"{}\", \n",
    "           \"slice\": \"{}\", \n",
    "           \"version\": \"v1\"\n",
    "        }},\\n'''.format(timestamp.isoformat(), datasetname + tag) \n",
    "\n",
    "\n",
    "    json = dataset.to_json(orient=\"records\", indent=4)\n",
    "\n",
    "    # add extra indent to the json so it fits into the final output\n",
    "    json = re.sub('\\n', '\\n    ', json)\n",
    "\n",
    "    if debug: print(\"write file data/{}/{}\".format(datasetname, name))\n",
    "    with open('data/'+datasetname+'/' + name,'w') as f:\n",
    "        f.write(fileinfo + '    \"playlists\": ' + json)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_set(test_challenge, testname, today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create challenge tasks\n",
    "\n",
    "this is where we process the task attributes to create two outputs from the challengeset:\n",
    "* the answer key - to compare results and compute the rating scores\n",
    "* the withheld format of the challengeset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_challenge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_challenge[[\"num_samples\", \"random\", \"with_title\" ]].iteritems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(test_challenge.shape[0]):\n",
    "        num_samples = test_challenge.iloc[index].num_samples\n",
    "        random = test_challenge.iloc[index].random\n",
    "        with_title = test_challenge.iloc[index].with_title\n",
    "        print(\"plist {}, num_samples {}, random {}, with_title {}\".format(index, num_samples, random, with_title))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_challenge.iloc[1].tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_out = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_challenge.iloc[0]['tracks'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testtracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_challenge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_out = pd.DataFrame()\n",
    "\n",
    "# for each playlist produce the correctly formatted output of withheld tracks\n",
    "\n",
    "for index in range(test_challenge.shape[0]):\n",
    "    num_samples = test_challenge.iloc[index].num_samples\n",
    "    random = test_challenge.iloc[index].random\n",
    "    with_title = test_challenge.iloc[index].with_title\n",
    "    if debug: print(\"plist {}, num_samples {}, random {}, with_title {}\".format(index, num_samples, random, with_title))\n",
    "\n",
    "    \n",
    "   \n",
    "    if  random:\n",
    "        # sample num_samples\n",
    "        #print(\"len {}, samples{}\".format(len(test_challenge.iloc[index]['tracks']), num_samples))\n",
    "        testtracks = rand.sample(test_challenge.iloc[index]['tracks'], num_samples)\n",
    "        testtracks = [sorted(testtracks, key=itemgetter('pos'))]\n",
    "    else:\n",
    "        #print(\"tracks type {}\".format(len(test_challenge.iloc[index]['tracks'])))\n",
    "        #print(test_challenge.iloc[index]['tracks'][0:3])\n",
    "        testtracks = [test_challenge.iloc[index]['tracks'][0:num_samples]]\n",
    "        #testtracks=[]\n",
    "  \n",
    "    if with_title:\n",
    "        testtitle = test_challenge.iloc[index]['name']\n",
    "    else:\n",
    "        testtitle = \"\"\n",
    "    \n",
    "    num_tracks = test_challenge.iloc[index]['num_tracks']\n",
    "    num_holdouts = num_tracks - num_samples\n",
    "    pid = 2000000 + index\n",
    "\n",
    "    entry = pd.DataFrame([(testtitle, num_holdouts, pid, num_tracks, num_samples)], columns=('name', 'num_holdouts', 'pid', 'num_tracks', 'num_samples'), index=[index])\n",
    "    entry['tracks'] = testtracks\n",
    "    \n",
    "    #print(entry)\n",
    "    \n",
    "    challenge_out = challenge_out.append(entry)\n",
    "    #print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_set(challenge_out, testname, today, name=\"ex2-challengeset.json\", tag=\"_challengeset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge set is created.\n",
    "\n",
    "Fix: header in output to match following but loose json interpretation should ignore it.\n",
    "```\n",
    "    \"date\": \"2018-01-16 08:47:28.198015\", \n",
    "    \"version\": \"v1\", \n",
    "    \"playlists\": [\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out challenge answer key is submit format\n",
    "\n",
    "This may make it easier to run the scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#challenge_out.iloc[6000].tracks[2]['track_uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(challenge_out.iloc[5001].tracks, key=itemgetter(\"pos\"), reverse=True) #[3][\"pos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_challenge"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
